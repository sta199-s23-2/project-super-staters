---
title: "Statistics of Music"
subtitle: "Report"
format: html
editor: visual
execute:
  echo: true
---

The source of this data is the Million Song Dataset. The National Science Foundation's project IIS-0713334 funded the Million Song Dataset with a grant. There were several curators for this dataset---the Million Song Dataset used a company called the Echo Nest to derive global data points about one million contemporary songs. It was also a collaboration between the Echo Nest and LabROSA (laboratory working towards intelligent machine listening). It was collected in 2011. There are 10,000 observations with different songs associated by a song ID and their respective artists that also have an artist ID. Every observation is also defined by several variables such as artist familiarity (the extent to which an artist's listeners are familiar with an artist's music), song tempo, song duration, year of a song's release, and many more. It is important to note that there are no audios in this dataset, only the derived features.

**Introduction and data**

The source of this data is the Million Song Dataset. The National Science Foundation's project IIS-0713334 funded the Million Song Dataset with a grant. There were several curators for this dataset; the Million Song Dataset used a company called the Echo Nest to derive global data points about one million contemporary songs. It was also a collaboration between the Echo Nest and LabROSA (laboratory working towards intelligent machine listening). It was collected in 2011. There are 10,000 observations with different songs associated by a song ID and their respective artists that also have an artist ID. Every observation is also defined by several variables such as artist familiarity, song loudness, song tempo, and many more. It is important to note that there are no audios in this dataset, only the derived features.

Previous literature exists about the topic. "Prediction of product success: explaining song popularity by audio features from Spotify data" attempts to explore the relation between song attributes such as tempo and key signature, as well as the number of plays on Spotify, the popular music-streaming platform. This paper uses a dataset of 1000 songs to investigate this question. Ultimately, the researchers find that there is only a fairly limited relation between song popularity (measured in stream count) and song features. In particular, the paper finds that tempo, which is the variable that we are most interested in, has no significant relation to stream count. Our research question builds on this article because we are similarly looking into audio features (like tempo) that make songs more popular but going further to see if a relation can be found conditional upon the genre (not an audio feature) associated with the artist a song.

Nijkamp, R. (2018). Prediction of product success: explaining song popularity by audio features from Spotify data (Bachelor's thesis, University of Twente). http://essay.utwente.nl/75422/1/NIJKAMP_BA_IBA.pdf

**Research Question**

Given a genre (Rock, Pop, Rap, or Country, chosen for their sizable amount of observations within the data set), associated with an artist (artist.terms), how are the relationships between different song attributes (such as song.tempo, song.duration, artist.familiarity, song.year) related to song popularity (song.hotttnesss)? Do these relations differ for artists associated with different genres?

**Methodology**

We first load our data.

```{r}
#| label: load-data

library(tidyverse)
library(tidymodels)

music <- read_csv("data/music.csv")
music_filter <- music |>
  filter(str_detect(artist.terms, "rock") |
         str_detect(artist.terms, "rap") |
         str_detect(artist.terms, "pop") |
         str_detect(artist.terms, "country"))

music_filter$rock_genre <- if_else(
  grepl("rock", music_filter$artist.terms), 
        "rock", "not rock")

music_filter$rap_genre <- if_else(
  grepl("rap", music_filter$artist.terms), 
        "rap", "not rap")

music_filter$pop_genre <- if_else(
  grepl("pop", music_filter$artist.terms), 
        "pop", "not pop")

music_filter$country_genre <- if_else(
  grepl("country", music_filter$artist.terms), 
        "country", "not country")

music_filter <- music_filter |>
  mutate(artist.terms = if_else(rock_genre == "rock", "Rock",
                        if_else(rap_genre == "rap", "Rap",
                        if_else(pop_genre == "pop", "Pop",
                        if_else(country_genre == "country", "Country", "")))))

```

Next, we plot linear regressions visually over a scatterplot to show the relation between four different song attributes (listed in our research question) and song popularity by our four genres of interest. We do this to get a general sense of how the song attributes might predict song popularity, which will help us answer our research question of how much each song attribute is correlated with a song's popularity.

```{r}
#| label: tempo-by-genre

music_filter |> 
  filter(song.hotttnesss >= 0) |>
  ggplot(
    aes(x = song.tempo, y = song.hotttnesss)) +
  geom_point() +
  geom_smooth(method = lm, se = F) +
  facet_wrap(~ artist.terms) +
  labs(x = "Tempo (BPM)", y = "Song popularity (rated from 0-1)",
       title = "The Relationship Between Song Tempo
       and Popularity by Genre")
  
```

```{r}
#| label: duration-by-genre

music_filter |> 
  filter(song.hotttnesss >= 0,
         song.duration < 1000) |>
  ggplot(
    aes(x = song.duration, y = song.hotttnesss)) +
  geom_point() +
  geom_smooth(method = lm, se = F) +
  facet_wrap(~ artist.terms) +
  labs(x = "Duration (seconds)", y = "Song popularity (rated from 0-1)",
       title = "The Relationship Between Song Duration
       and Popularity by Genre")
  
```

```{r}
#| label: familiarity-by-genre

music_filter |> 
  filter(song.hotttnesss >= 0) |>
  ggplot(
    aes(x = artist.familiarity, y = song.hotttnesss)) +
  geom_point() +
  geom_smooth(method = lm, se = F) +
  facet_wrap(~ artist.terms) +
  labs(x = "Familiarity (0-1 scale)", y = "Song popularity (rated from 0-1)",
       title = "The Relationship Between Song Duration
       and Popularity by Genre")
  
```

```{r}
#| label: year-by-genre

music_filter |> 
  filter(song.hotttnesss >= 0,
         song.year > 0) |>
  ggplot(
    aes(x = song.year, y = song.hotttnesss)) +
  geom_point() +
  geom_smooth(method = lm, se = F) +
  facet_wrap(~ artist.terms) +
  labs(x = "Year", y = "Song popularity (rated from 0-1)",
       title = "The Relationship Between Song Duration
       and Popularity by Genre")
  
```


Finally, we run interactive regression models to measure the interactive effect between artist.terms (genre associated with an artist) and respective song attributes on song popularity (song.hotttnesss). We believe that an interactive model is useful in answering our research question because we are interested in the extent to which different song attributes predict song popularity, based on the genre associated with the artist. The predictions made by our interactive model can thus be broken down into the different predicted effects for each genre, which directly helps us answer our research question. Additionally, we are able to calculate the AIC and adjusted R-squared value of each model to determine which model is the greatest fit, and thus which may possibly have the most significant predictve power, which will also help us answer our question of the extent to which different song attributes predict song popularity.

```{r}
#| label: int-model-tempo

int_model_tempo <- linear_reg() |>
  set_engine("lm") |>
  fit(song.hotttnesss ~ artist.terms * song.tempo, data = music_filter)
    
tidy(int_model_tempo)
```

From the above regression, we are getting the following estimations for each genre (where Country is our "baseline" genre):

Country:
$\widehat{song.hotttness} = -0.370642967 -0.000534460 * song.tempo$

Pop:
$\widehat{song.hotttness} = -0.370642967 - 0.215690672 + (-0.000534460 + 0.00303) * song.tempo = -0.586333639 + 0.00249554* song.tempo$

Rap:
$\widehat{song.hotttness} = -0.370642967 + 0.475038439 + (-0.000534460 -0.001126495) * song.tempo = 0.104395472 - 0.001660955 * song.tempo$

Rock:
$\widehat{song.hotttness} = -0.370642967 + 0.301058002 + (-0.000534460 + 0.000115371) * song.tempo = -0.069584965 - 0.000419089 * song.tempo$

(Interpretation?)


```{r}
#| label: int-model-duration

int_model_duration <- linear_reg() |>
  set_engine("lm") |>
  fit(song.hotttnesss ~ artist.terms * song.duration, data = music_filter)
    
tidy(int_model_duration)
```

From the above regression, we are getting the following estimations for each genre (where Country is our "baseline" genre):

Country:
$\widehat{song.hotttness} = -0.949 + 0.00267 * song.duration$

Pop:
$\widehat{song.hotttness} = -0.949 + 0.712 + (0.00267 - 0.00285) * song.duration = -0.237 - 0.00018 * song.duration$

Rap:
$\widehat{song.hotttness} = -0.949 + 1.08 + (0.00267 - 0.00363) * song.duration = 0.131 - 0.00096 * song.duration$

Rock:
$\widehat{song.hotttness} = -0.949 + 0.758 + (0.00267 - 0.00239) * song.duration = -0.191 + 0.00028 * song.duration$

(Interpretation?)

```{r}
#| label: int-model-familiarity

int_model_familiarity <- linear_reg() |>
  set_engine("lm") |>
  fit(song.hotttnesss ~ artist.terms * artist.familiarity, data = music_filter)
    
tidy(int_model_familiarity)
```

From the above regression, we are getting the following estimations for each genre (where Country is our "baseline" genre):

Country:
$\widehat{song.hotttness} = -0.958 + 1.01 * artist.familiarity$

Pop:
$\widehat{song.hotttness} = -0.958 - 0.0320 + (1.01 + 0.175) * artist.familiarity = -0.99 +  1.185 * artist.familiarity$

Rap:
$\widehat{song.hotttness} = -0.958 + 0.836 + (1.01 - 0.977) * artist.familiarity = -0.122 + 0.033 * artist.familiarity$

Rock:
$\widehat{song.hotttness} = -0.958 + 0.299 + (1.01 - 0.135) * artist.familiarity = -0.659 + 0.875 * artist.familiarity$

(Interpretation?)

```{r}
#| label: int-model-year

int_model_year <- linear_reg() |>
  set_engine("lm") |>
  fit(song.hotttnesss ~ artist.terms * song.year, data = music_filter)

tidy(int_model_year)
```

From the above regression, we are getting the following estimations for each genre (where Country is our "baseline" genre):

Country:
$\widehat{song.hotttness} = -0.470 + 0.0000399 * song.year$

Pop:
$\widehat{song.hotttness} = -0.470 - 0.0288 + (0.0000399 + 0.000187) * song.year = -0.4988 +  0.0002269 * song.year$

Rap:
$\widehat{song.hotttness} = -0.470 + 0.251 + (0.0000399 + 0.0000755) * song.year = -0.219 + 0.0001154 * song.year$

Rock:
$\widehat{song.hotttness} = -0.470 + 0.182 + (0.0000399 + 0.000105) * song.year = -0.288 + 0.0001449 * song.year$

(Interpretation?)

```{r}
#| label: aic-r-sq

glance(int_model_tempo)$adj.r.squared
glance(int_model_tempo)$AIC

glance(int_model_duration)$adj.r.squared
glance(int_model_duration)$AIC

glance(int_model_familiarity)$adj.r.squared
glance(int_model_familiarity)$AIC

glance(int_model_year)$adj.r.squared
glance(int_model_year)$AIC
```

(interpretation)
